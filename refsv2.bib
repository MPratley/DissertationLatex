
@book{anderson_kanban_2010,
  title = {Kanban: {{Successful Evolutionary Change}} for {{Your Technology Business}}},
  author = {Anderson, David J},
  date = {2010},
  publisher = {{Blue Hole Press}},
  url = {https://play.google.com/store/books/details?id=RJ0VUkfUWZkC},
  abstract = {"Kanban is becoming a popular way to visualize and limit work-in-progress
in software development and information technology work. Teams around the
world are adding Kanban around their existing processes to catalyze
cultural change and deliver better business agility. David J. Anderson
pioneered the Kanban Method. Hear how this happened and what you can do to
succeed using Kanban."--Publisher's website.},
  isbn = {978-0-9845214-0-1},
  pagetotal = {261}
}

@article{bostrom_whole_2008,
  title = {Whole {{Brain Emulation}}: {{A Roadmap}}},
  author = {Bostrom, Nick and Sandberg, Anders},
  date = {2008},
  journaltitle = {Technical Report \#2008‐3},
  volume = {Future of Humanity Institute, Oxford University},
  file = {/home/marcus/Zotero/storage/2FTXI6QV/Bostrom and Sandberg - Whole Brain Emulation A Roadmap.pdf},
  langid = {english}
}

@article{eglen_data_2014,
  title = {A Data Repository and Analysis Framework for Spontaneous Neural Activity Recordings in Developing Retina},
  author = {Eglen, Stephen John and Weeks, Michael and Jessop, Mark and Simonotto, Jennifer and Jackson, Tom and Sernagor, Evelyne},
  date = {2014-12-01},
  journaltitle = {GigaScience},
  shortjournal = {Gigascience},
  volume = {3},
  doi = {10.1186/2047-217X-3-3},
  url = {https://academic.oup.com/gigascience/article/3/1/2047-217X-3-3/2682913},
  urldate = {2019-12-03},
  abstract = {AbstractBackground:.  During early development, neural circuits fire spontaneously, generating activity episodes with complex spatiotemporal patterns. Recording},
  file = {/home/marcus/Zotero/storage/FI7FQFSQ/Eglen et al. - 2014 - A data repository and analysis framework for spont.pdf;/home/marcus/Zotero/storage/B8B4MYY9/2682913.html},
  langid = {english},
  number = {1}
}

@article{einevoll_scientific_2019,
  title = {The {{Scientific Case}} for {{Brain Simulations}}},
  author = {Einevoll, Gaute T and Destexhe, Alain and Diesmann, Markus and Grün, Sonja and Jirsa, Viktor and de Kamps, Marc and Migliore, Michele and Ness, Torbjørn V and Plesser, Hans E and Schürmann, Felix},
  date = {2019-05-22},
  journaltitle = {Neuron},
  volume = {102},
  pages = {735--744},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.03.027},
  url = {http://dx.doi.org/10.1016/j.neuron.2019.03.027},
  abstract = {A key element of the European Union's Human Brain Project (HBP) and other
large-scale brain research projects is the simulation of large-scale model
networks of neurons. Here, we argue why such simulations will likely be
indispensable for bridging the scales between the neuron and system levels
in the brain, and why a set of brain simulators based on neuron models at
different levels of biological detail should therefore be developed. To
allow for systematic refinement of candidate network models by comparison
with experiments, the simulations should be multimodal in the sense that
they should predict not only action potentials, but also electric,
magnetic, and optical signals measured at the population and system
levels.},
  file = {/home/marcus/Zotero/storage/BWDGUJIZ/Einevoll et al. - 2019 - The Scientific Case for Brain Simulations.pdf},
  keywords = {brain simulation,model,network,neuron,simulation,simulator},
  number = {4},
  options = {useprefix=true}
}

@inproceedings{folk_overview_2011,
  title = {An Overview of the {{HDF5}} Technology Suite and Its Applications},
  booktitle = {Proceedings of the {{EDBT}}/{{ICDT}} 2011 {{Workshop}} on {{Array Databases}} - {{AD}} '11},
  author = {Folk, Mike and Heber, Gerd and Koziol, Quincey and Pourmal, Elena and Robinson, Dana},
  date = {2011},
  pages = {36--47},
  publisher = {{ACM Press}},
  location = {{Uppsala, Sweden}},
  doi = {10.1145/1966895.1966900},
  url = {http://portal.acm.org/citation.cfm?doid=1966895.1966900},
  urldate = {2019-12-05},
  abstract = {In this paper, we give an overview of the HDF5 technology suite and some of its applications. We discuss the HDF5 data model, the HDF5 software architecture and some of its performance enhancing capabilities.},
  eventtitle = {The {{EDBT}}/{{ICDT}} 2011 {{Workshop}}},
  file = {/home/marcus/Zotero/storage/5P288AEE/Folk et al. - 2011 - An overview of the HDF5 technology suite and its a.pdf;/home/marcus/Zotero/storage/U5IUEHAN/a5-folk.pdf},
  isbn = {978-1-4503-0614-0},
  langid = {english}
}

@article{hagen_hybrid_2016,
  title = {Hybrid {{Scheme}} for {{Modeling Local Field Potentials}} from {{Point}}-{{Neuron Networks}}},
  author = {Hagen, Espen and Dahmen, David and Stavrinou, Maria L and Lindén, Henrik and Tetzlaff, Tom and van Albada, Sacha J and Grün, Sonja and Diesmann, Markus and Einevoll, Gaute T},
  date = {2016-12},
  journaltitle = {Cereb. Cortex},
  volume = {26},
  pages = {4461--4496},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw237},
  url = {http://dx.doi.org/10.1093/cercor/bhw237},
  abstract = {With rapidly advancing multi-electrode recording technology, the local
field potential (LFP) has again become a popular measure of neuronal
activity in both research and clinical applications. Proper understanding
of the LFP requires detailed mathematical modeling incorporating the
anatomical and electrophysiological features of neurons near the recording
electrode, as well as synaptic inputs from the entire network. Here we
propose a hybrid modeling scheme combining efficient point-neuron network
models with biophysical principles underlying LFP generation by real
neurons. The LFP predictions rely on populations of network-equivalent
multicompartment neuron models with layer-specific synaptic connectivity,
can be used with an arbitrary number of point-neuron network populations,
and allows for a full separation of simulated network dynamics and LFPs.
We apply the scheme to a full-scale cortical network model for a ∼1 mm2
patch of primary visual cortex, predict laminar LFPs for different network
states, assess the relative LFP contribution from different laminar
populations, and investigate effects of input correlations and neuron
density on the LFP. The generic nature of the hybrid scheme and its public
implementation in hybridLFPy form the basis for LFP predictions from other
and larger point-neuron network models, as well as extensions of the
current application with additional biological detail.},
  file = {/home/marcus/Zotero/storage/WDQSTAWR/Hagen et al. - 2016 - Hybrid Scheme for Modeling Local Field Potentials .pdf},
  keywords = {cortical microcircuit,electrostatic forward modeling,extracellular potential,multicompartment neuron modeling,point-neuron network models},
  number = {12},
  options = {useprefix=true}
}

@incollection{hagen_lfpy_2019,
  title = {{{LFPy}}: {{Multimodal Modeling}} of {{Extracellular Neuronal Recordings}} in {{Python}}},
  booktitle = {Encyclopedia of {{Computational Neuroscience}}},
  author = {Hagen, Espen and Næss, Solveig and Ness, Torbjørn V and Einevoll, Gaute T},
  editor = {Jaeger, Dieter and Jung, Ranu},
  date = {2019},
  pages = {1--10},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4614-7320-6_100681-1},
  url = {https://doi.org/10.1007/978-1-4614-7320-6_100681-1},
  file = {/home/marcus/Zotero/storage/PVADW5EJ/Hagen et al. - 2019 - LFPy Multimodal Modeling of Extracellular Neurona.pdf},
  isbn = {978-1-4614-7320-6}
}

@article{huang_jenetics_nodate,
  title = {{{JENETICS LIBRARY USER}}'{{S MANUAL}} 4.1},
  author = {Huang, Yuchen},
  url = {https://www.academia.edu/36432279/JENETICS_LIBRARY_USERS_MANUAL_4.1},
  urldate = {2019-11-12},
  abstract = {JENETICS LIBRARY USER'S MANUAL 4.1}
}

@article{james_kennedy_particle_1995,
  title = {Particle Swarm Optimization},
  author = {James Kennedy, Russell Eberhart},
  date = {1995},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.248.4138},
  urldate = {2019-11-13},
  abstract = {CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.},
  file = {/home/marcus/Zotero/storage/VHDFUVLW/James Kennedy - 1995 - Particle swarm optimization.pdf}
}

@article{jiang_stochastic_2007,
  title = {Stochastic Convergence Analysis and Parameter Selection of the Standard Particle Swarm Optimization Algorithm},
  author = {Jiang, M. and Luo, Y. P. and Yang, S. Y.},
  date = {2007-04-15},
  journaltitle = {Information Processing Letters},
  shortjournal = {Information Processing Letters},
  volume = {102},
  pages = {8--16},
  issn = {0020-0190},
  doi = {10.1016/j.ipl.2006.10.005},
  url = {http://www.sciencedirect.com/science/article/pii/S0020019006003103},
  urldate = {2019-11-14},
  abstract = {This letter presents a formal stochastic convergence analysis of the standard particle swarm optimization (PSO) algorithm, which involves with randomness. By regarding each particle's position on each evolutionary step as a stochastic vector, the standard PSO algorithm determined by non-negative real parameter tuple \{ω,c1,c2\} is analyzed using stochastic process theory. The stochastic convergent condition of the particle swarm system and corresponding parameter selection guidelines are derived.},
  file = {/home/marcus/Zotero/storage/YP77GQIT/Jiang et al. - 2007 - Stochastic convergence analysis and parameter sele.pdf;/home/marcus/Zotero/storage/2Z8J4K8V/S0020019006003103.html},
  keywords = {Analysis of algorithms,Parameter selection,Particle swarm optimization,Stochastic convergence analysis,Stochastic optimization},
  langid = {english},
  number = {1}
}

@article{jirsa_virtual_2017,
  title = {The {{Virtual Epileptic Patient}}: {{Individualized}} Whole-Brain Models of Epilepsy Spread},
  shorttitle = {The {{Virtual Epileptic Patient}}},
  author = {Jirsa, V. K. and Proix, T. and Perdikis, D. and Woodman, M. M. and Wang, H. and Gonzalez-Martinez, J. and Bernard, C. and Bénar, C. and Guye, M. and Chauvel, P. and Bartolomei, F.},
  date = {2017-01-15},
  journaltitle = {NeuroImage},
  shortjournal = {Neuroimage},
  volume = {145},
  pages = {377--388},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2016.04.049},
  abstract = {Individual variability has clear effects upon the outcome of therapies and treatment approaches. The customization of healthcare options to the individual patient should accordingly improve treatment results. We propose a novel approach to brain interventions based on personalized brain network models derived from non-invasive structural data of individual patients. Along the example of a patient with bitemporal epilepsy, we show step by step how to develop a Virtual Epileptic Patient (VEP) brain model and integrate patient-specific information such as brain connectivity, epileptogenic zone and MRI lesions. Using high-performance computing, we systematically carry out parameter space explorations, fit and validate the brain model against the patient's empirical stereotactic EEG (SEEG) data and demonstrate how to develop novel personalized strategies towards therapy and intervention.},
  eprint = {27477535},
  eprinttype = {pmid},
  file = {/home/marcus/Zotero/storage/5MEQ6CG2/Jirsa et al. - 2017 - The Virtual Epileptic Patient Individualized whol.pdf;/home/marcus/Zotero/storage/92PQ69R5/Jirsa et al. - 2017 - The Virtual Epileptic Patient Individualized whol.pdf},
  issue = {Pt B},
  keywords = {Epilepsy,Female,Humans,Magnetic Resonance Imaging,Models; Theoretical,Precision Medicine},
  langid = {english}
}

@article{karlik_performance_nodate,
  title = {Performance {{Analysis}} of {{Various Activation Functions}} in {{Generalized MLP Architectures}} of {{Neural Networks}}},
  author = {Karlik, Bekir and Olgac, A Vehbi},
  pages = {12},
  abstract = {The activation function used to transform the activation level of a unit (neuron) into an output signal. There are a number of common activation functions in use with artificial neural networks (ANN). The most common choice of activation functions for multi layered perceptron (MLP) is used as transfer functions in research and engineering. Among the reasons for this popularity are its boundedness in the unit interval, the function’s and its derivative’s fast computability, and a number of amenable mathematical properties in the realm of approximation theory. However, considering the huge variety of problem domains MLP is applied in, it is intriguing to suspect that specific problems call for single or a set of specific activation functions. The aim of this study is to analyze the performance of generalized MLP architectures which has back-propagation algorithm using various different activation functions for the neurons of hidden and output layers. For experimental comparisons, Bi-polar sigmoid, Uni-polar sigmoid, Tanh, Conic Section, and Radial Bases Function (RBF) were used.},
  file = {/home/marcus/Zotero/storage/KQ6LCMKM/Karlik and Olgac - Performance Analysis of Various Activation Functio.pdf},
  langid = {english}
}

@book{kurzweil_singularity_2006,
  title = {The Singularity Is near: When Humans Transcend Biology},
  author = {Kurzweil, Ray},
  date = {2006},
  edition = {1st},
  publisher = {{Penguin Books}}
}

@online{noauthor_doi10.1016/j.ipl.2006.10.005_nodate,
  title = {Doi:10.1016/j.Ipl.2006.10.005 | {{Elsevier Enhanced Reader}}},
  shorttitle = {Doi},
  doi = {10.1016/j.ipl.2006.10.005},
  url = {https://reader.elsevier.com/reader/sd/pii/S0020019006003103?token=0499CFC18DC215A46D9A311A7ADD75E5C4EE867E64141EA56A1019DC6910D8D371FB7D84EC894DBC334873B309BA71DB},
  urldate = {2019-11-14},
  file = {/home/marcus/Zotero/storage/KQG5LTG3/S0020019006003103.html},
  langid = {english}
}

@online{noauthor_ray_nodate,
  title = {Ray Kurzweil Singularity - {{Google Search}}},
  url = {https://www.google.com/search?q=ray+kurzweil+singularity&oq=ray+kurzweil+&aqs=chrome.3.69i57j0l7.5234j1j9&sourceid=chrome&ie=UTF-8},
  urldate = {2019-12-06},
  file = {/home/marcus/Zotero/storage/D6DBDENK/search.html}
}

@article{olmi_controlling_2019,
  title = {Controlling Seizure Propagation in Large-Scale Brain Networks},
  author = {Olmi, Simona and Petkoski, Spase and Guye, Maxime and Bartolomei, Fabrice and Jirsa, Viktor},
  date = {2019-02-25},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {15},
  pages = {e1006805},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006805},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006805},
  urldate = {2019-12-04},
  abstract = {Information transmission in the human brain is a fundamentally dynamic network process. In partial epilepsy, this process is perturbed and highly synchronous seizures originate in a local network, the so-called epileptogenic zone (EZ), before recruiting other close or distant brain regions. We studied patient-specific brain network models of 15 drug-resistant epilepsy patients with implanted stereotactic electroencephalography (SEEG) electrodes. Each personalized brain model was derived from structural data of magnetic resonance imaging (MRI) and diffusion tensor weighted imaging (DTI), comprising 88 nodes equipped with region specific neural mass models capable of demonstrating a range of epileptiform discharges. Each patient’s virtual brain was further personalized through the integration of the clinically hypothesized EZ. Subsequent simulations and connectivity modulations were performed and uncovered a finite repertoire of seizure propagation patterns. Across patients, we found that (i) patient-specific network connectivity is predictive for the subsequent seizure propagation pattern; (ii) seizure propagation is characterized by a systematic sequence of brain states; (iii) propagation can be controlled by an optimal intervention on the connectivity matrix; (iv) the degree of invasiveness can be significantly reduced via the proposed seizure control as compared to traditional resective surgery. To stop seizures, neurosurgeons typically resect the EZ completely. We showed that stability analysis of the network dynamics, employing structural and dynamical information, estimates reliably the spatiotemporal properties of seizure propagation. This suggests novel less invasive paradigms of surgical interventions to treat and manage partial epilepsy.},
  file = {/home/marcus/Zotero/storage/SBWJGHY6/Olmi et al. - 2019 - Controlling seizure propagation in large-scale bra.pdf;/home/marcus/Zotero/storage/Q294T7X9/article.html},
  keywords = {Eigenvalues,Eigenvectors,Epilepsy,Lesions,Network analysis,Neural networks,Surgical and invasive medical procedures,Surgical resection},
  langid = {english},
  number = {2}
}

@article{poli_particle_2007,
  title = {Particle Swarm Optimization: {{An}} Overview},
  shorttitle = {Particle Swarm Optimization},
  author = {Poli, Riccardo and Kennedy, James and Blackwell, Tim},
  date = {2007-10-17},
  journaltitle = {Swarm Intelligence},
  shortjournal = {Swarm Intell},
  volume = {1},
  pages = {33--57},
  issn = {1935-3812, 1935-3820},
  doi = {10.1007/s11721-007-0002-0},
  url = {http://link.springer.com/10.1007/s11721-007-0002-0},
  urldate = {2019-11-14},
  abstract = {Particle swarm optimization (PSO) has undergone many changes since its introduction in 1995. As researchers have learned about the technique, they have derived new versions, developed new applications, and published theoretical studies of the effects of the various parameters and aspects of the algorithm. This paper comprises a snapshot of particle swarming from the authors’ perspective, including variations in the algorithm, current and ongoing research, applications and open problems.},
  file = {/home/marcus/Zotero/storage/NJW4F5KF/Poli et al. - 2007 - Particle swarm optimization An overview.pdf},
  langid = {english},
  number = {1}
}

@article{proix_predicting_2018,
  title = {Predicting the Spatiotemporal Diversity of Seizure Propagation and Termination in Human Focal Epilepsy},
  author = {Proix, Timothée and Jirsa, Viktor K. and Bartolomei, Fabrice and Guye, Maxime and Truccolo, Wilson},
  date = {2018-03-14},
  journaltitle = {Nature Communications},
  volume = {9},
  pages = {1--15},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-02973-y},
  url = {https://www.nature.com/articles/s41467-018-02973-y},
  urldate = {2019-12-04},
  abstract = {A major goal of epilepsy research is understanding the spatiotemporal dynamics of seizure. Here, the authors extend the Epileptor neural mass model into a neural field model, in order to provide a unified and patient-specific model of seizure initiation, propagation, and termination.},
  file = {/home/marcus/Zotero/storage/S7854W3L/Proix et al. - 2018 - Predicting the spatiotemporal diversity of seizure.pdf;/home/marcus/Zotero/storage/YJ8D5KEQ/s41467-018-02973-y.html},
  langid = {english},
  number = {1}
}

@thesis{puranik_is_2018,
  title = {Is {{Singularity Near}}? {{Predicting Future Brain Activity Using}} a {{Computational Model}}},
  author = {Puranik, Himanshu Nityanand},
  date = {2018},
  institution = {{Newcastle University}}
}

@article{saighi_plasticity_2015,
  title = {Plasticity in Memristive Devices for Spiking Neural Networks},
  author = {Saïghi, Sylvain and Mayr, Christian G. and Serrano-Gotarredona, Teresa and Schmidt, Heidemarie and Lecerf, Gwendal and Tomas, Jean and Grollier, Julie and Boyn, Sören and Vincent, Adrien F. and Querlioz, Damien and La Barbera, Selina and Alibart, Fabien and Vuillaume, Dominique and Bichler, Olivier and Gamrat, Christian and Linares-Barranco, Bernabé},
  date = {2015},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {9},
  issn = {1662-453X},
  doi = {10.3389/fnins.2015.00051},
  url = {https://www.frontiersin.org/articles/10.3389/fnins.2015.00051/full},
  urldate = {2020-02-23},
  abstract = {Memristive devices present a new device technology allowing for the realization of compact nonvolatile memories. Some of them are already in the process of industrialization. Additionally, they exhibit complex multilevel and plastic behaviors, which make them good candidates for the implementation of artificial synapses in neuromorphic engineering. However, memristive effects rely on diverse physical mechanisms, and their plastic behaviors differ strongly from one technology to another. Here, we present measurements performed on different memristive devices and the opportunities that they provide. We show that they can be used to implement different learning rules whose properties emerge directly from device physics: real time or accelerated operation, deterministic or stochastic behavior, long term or short term plasticity. We then discuss how such devices might be integrated into a complete architecture. These results highlight that there is no unique way to exploit memristive devices in neuromorphic systems. Understanding and embracing device physics is the key for their optimal use.},
  file = {/home/marcus/Zotero/storage/A6E2L4HM/Saïghi et al. - 2015 - Plasticity in memristive devices for spiking neura.pdf},
  keywords = {Hardware neural network,Memristive device,Memristor,neuromorphic engineering,plasticity},
  langid = {english}
}

@article{schemmel_implementing_nodate,
  title = {Implementing {{Synaptic Plasticity}} in a {{VLSI Spiking Neural Network Model}}},
  author = {Schemmel, Johannes and Grubl, Andreas and Meier, Karlheinz and Mueller, Eilif},
  pages = {6},
  abstract = {This paper describes an area-efficient mixed-signal implementation of synapse-based long term plasticity realized in a VLSI1 model of a spiking neural network. The artificial synapses are based on an implementation of spike time dependent plasticity (STDP). In the biological specimen, STDP is a mechanism acting locally in each synapse. The presented electronic implementation succeeds in maintaining this high level of parallelism and simultaneously achieves a synapse density of more than 9k synapses per mm2 in a 180 nm technology. This allows the construction of neural micro-circuits close to the biological specimen while maintaining a speed several orders of magnitude faster than biological real time. The large acceleration factor enhances the possibilities to investigate key aspects of plasticity, e.g. by performing extensive parameter searches.},
  file = {/home/marcus/Zotero/storage/84ZXHYXT/Schemmel et al. - Implementing Synaptic Plasticity in a VLSI Spiking.pdf},
  langid = {english}
}

@article{soderquist_area_1996,
  title = {Area and {{Performance Tradeoffs}} in {{Floating}}-Point {{Divide}} and {{Square}}-Root {{Implementations}}},
  author = {Soderquist, Peter and Leeser, Miriam},
  date = {1996-09},
  journaltitle = {ACM Comput. Surv.},
  volume = {28},
  pages = {518--564},
  issn = {0360-0300},
  doi = {10.1145/243439.243481},
  url = {http://doi.acm.org/10.1145/243439.243481},
  urldate = {2019-12-12},
  abstract = {Floating-point divide and square-root operations are essential to many scientific and engineering applications, and are required in all computer systems that support the IEEE floating-point standard. Yet many current microprocessors provide only weak support for these operations. The latency and throughput of division are typically far inferior to those of floating-point addition and multiplication, and square-root performance is often even lower. This article argues the case for high-performance division and square root. It also explains the algorithms and implementations of the primary techniques, subtractive and multiplicative methods, employed in microprocessor floating-point units with their associated area/performance tradeoffs. Case studies of representative floating-point unit configurations are presented, supported by simulation results using a carefully selected benchmark, Givens rotation, to show the dynamic performance impact of the various implementation alternatives. The topology of the implementation is found to be an important performance factor. Multiplicative algorithms, such as the Newton-Raphson method and Goldschmidt's algorithm, can achieve low latencies. However, these implementations serialize multiply, divide, and square root operations through a single pipeline, which can lead to low throughput. While this hardware sharing yields low size requirements for baseline implementations, lower-latency versions require many times more area. For these reasons, multiplicative implementations are best suited to cases where subtractive methods are precluded by area constraints, and modest performance on divide and square root operations is tolerable. Subtractive algorithms, exemplified by radix-4 SRT and radix-16 SRT, can be made to execute in parallel with other floating-point operations.},
  keywords = {area and performance tradeoffs,division,floating-point,FPU,square root,SRT},
  number = {3}
}

@article{sporns_organization_2004,
  title = {Organization, Development and Function of Complex Brain Networks},
  author = {Sporns, Olaf and Chialvo, Dante R and Kaiser, Marcus and Hilgetag, Claus C},
  date = {2004-09},
  journaltitle = {Trends Cogn. Sci.},
  volume = {8},
  pages = {418--425},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2004.07.008},
  url = {http://dx.doi.org/10.1016/j.tics.2004.07.008},
  abstract = {Recent research has revealed general principles in the structural and
functional organization of complex networks which are shared by various
natural, social and technological systems. This review examines these
principles as applied to the organization, development and function of
complex brain networks. Specifically, we examine the structural properties
of large-scale anatomical and functional brain networks and discuss how
they might arise in the course of network growth and rewiring. Moreover,
we examine the relationship between the structural substrate of
neuroanatomy and more dynamic functional and effective connectivity
patterns that underlie human cognition. We suggest that network analysis
offers new fundamental insights into global and integrative aspects of
brain function, including the origin of flexible and coherent cognitive
states within the neural architecture.},
  file = {/home/marcus/Zotero/storage/VJEBIWH4/Sporns et al. - 2004 - Organization, development and function of complex .pdf},
  number = {9}
}

@article{stathakis_how_2009,
  title = {How Many Hidden Layers and Nodes?},
  author = {Stathakis, D.},
  date = {2009-04-20},
  journaltitle = {International Journal of Remote Sensing},
  volume = {30},
  pages = {2133--2147},
  issn = {0143-1161},
  doi = {10.1080/01431160802549278},
  url = {https://doi.org/10.1080/01431160802549278},
  urldate = {2019-12-12},
  abstract = {The question of how many hidden layers and how many hidden nodes should there be always comes up in any classification task of remotely sensed data using neural networks. Until today there has been no exact solution. A method of shedding some light to this question is presented in this paper. A near‐optimal solution is discovered after searching with a genetic algorithm. A novel fitness function is introduced that concurrently seeks for the most accurate and compact solution. The proposed method is thoroughly compared to many other methods currently in use, including several heuristics and pruning algorithms. The results are encouraging, indicating that it is time to shift our focus from suboptimal practices to efficient search methods, to tune the parameters of neural networks.},
  file = {/home/marcus/Zotero/storage/GTHH4UY2/01431160802549278.html},
  number = {8}
}

@article{thornton_virtual_2019,
  title = {The {{Virtual Electrode Recording Tool}} for {{EXtracellular Potentials}} ({{VERTEX}}) {{Version}} 2.0: {{Modelling}} in Vitro Electrical Stimulation of Brain Tissue},
  author = {Thornton, Christopher and Hutchings, Frances and Kaiser, Marcus},
  date = {2019-02-01},
  journaltitle = {Wellcome Open Res},
  volume = {4},
  pages = {20},
  issn = {2398-502X},
  doi = {10.12688/wellcomeopenres.15058.1},
  url = {http://dx.doi.org/10.12688/wellcomeopenres.15058.1},
  abstract = {Neuronal circuits can be modelled in detail allowing us to predict the
effects of stimulation on individual neurons. Electrical stimulation of
neuronal circuits in vitro and in vivo excites a range of neurons within
the tissue and measurements of neural activity, e.g the local field
potential (LFP), are again an aggregate of a large pool of cells. The
previous version of our Virtual Electrode Recording Tool for EXtracellular
Potentials (VERTEX) allowed for the simulation of the LFP generated by a
patch of brain tissue. Here, we extend VERTEX to simulate the effect of
electrical stimulation through a focal electric field. We observe both
direct changes in neural activity and changes in synaptic plasticity.
Testing our software in a model of a rat neocortical slice, we determine
the currents contributing to the LFP, the effects of paired pulse
stimulation to induce short term plasticity (STP), and the effect of theta
burst stimulation (TBS) to induce long term potentiation (LTP).},
  file = {/home/marcus/Zotero/storage/YVLXTBG8/Thornton et al. - 2019 - The Virtual Electrode Recording Tool for EXtracell.pdf},
  keywords = {Electrical Stimulation,Local Field Potential,Long Term Potentiation,Neocortex,Short Term Plasticity,Spike-timing Dependent Plasticity,Synaptic Plasticity}
}

@article{ting_selecting_2009,
  title = {Selecting Survivors in Genetic Algorithm Using Tabu Search Strategies},
  author = {Ting, Chuan-Kang and Ko, Cheng-Feng and Huang, Chih-Hui},
  date = {2009-09-01},
  journaltitle = {Memetic Computing},
  shortjournal = {Memetic Comp.},
  volume = {1},
  pages = {191},
  issn = {1865-9292},
  doi = {10.1007/s12293-009-0013-z},
  url = {https://doi.org/10.1007/s12293-009-0013-z},
  urldate = {2019-12-12},
  abstract = {Genetic algorithm (GA) is well-known for its effectiveness in global search and optimization. To balance selection pressure and population diversity is an important issue of designing GA. This paper proposes a novel hybridization of GA and tabu search (TS) to address this issue. The proposed method embeds the key elements of TS—tabu restriction and aspiration criterion—into the survival selection operator of GA. More specifically, the tabu restriction is used to prevent inbreeding for diversity maintenance, and the aspiration criterion is activated to provide moderate selection pressure under the tabu restriction. The interaction of tabu restriction and aspiration criterion enables survivor selection to balance selection pressure and population diversity. The experimental results on numerical and combinatorial optimization problems show that this hybridization can significantly improve GAs in terms of solution quality as well as convergence speed. An empirical analysis further identifies the influences of the TS strategies on the performance of this hybrid GA.},
  file = {/home/marcus/Zotero/storage/GQBTSVAU/Ting et al. - 2009 - Selecting survivors in genetic algorithm using tab.pdf},
  keywords = {Genetic algorithm,Hybridization,Survival selection,Tabu search},
  langid = {english},
  number = {3}
}

@online{tomsett_tutorials_nodate,
  title = {Tutorials {{Archives}} - {{VERTEX}}},
  author = {Tomsett, R J},
  url = {http://vertexsimulator.org/category/tutorials/},
  urldate = {2019-11-04},
  langid = {english}
}

@article{tomsett_virtual_2015,
  title = {Virtual {{Electrode Recording Tool}} for {{EXtracellular}} Potentials ({{VERTEX}}): Comparing Multi-Electrode Recordings from Simulated and Biological Mammalian Cortical Tissue},
  author = {Tomsett, Richard J and Ainsworth, Matt and Thiele, Alexander and Sanayei, Mehdi and Chen, Xing and Gieselmann, Marc A and Whittington, Miles A and Cunningham, Mark O and Kaiser, Marcus},
  date = {2015-07},
  journaltitle = {Brain Struct. Funct.},
  volume = {220},
  pages = {2333--2353},
  issn = {1863-2653},
  doi = {10.1007/s00429-014-0793-x},
  url = {http://dx.doi.org/10.1007/s00429-014-0793-x},
  abstract = {Local field potentials (LFPs) sampled with extracellular electrodes are
frequently used as a measure of population neuronal activity. However,
relating such measurements to underlying neuronal behaviour and
connectivity is non-trivial. To help study this link, we developed the
Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX). We
first identified a reduced neuron model that retained the spatial and
frequency filtering characteristics of extracellular potentials from
neocortical neurons. We then developed VERTEX as an easy-to-use Matlab
tool for simulating LFPs from large populations ({$>$}100,000 neurons). A
VERTEX-based simulation successfully reproduced features of the LFPs from
an in vitro multi-electrode array recording of macaque neocortical tissue.
Our model, with virtual electrodes placed anywhere in 3D, allows direct
comparisons with the in vitro recording setup. We envisage that VERTEX
will stimulate experimentalists, clinicians, and computational
neuroscientists to use models to understand the mechanisms underlying
measured brain dynamics in health and disease.},
  file = {/home/marcus/Zotero/storage/79FRSQU8/Tomsett et al. - 2015 - Virtual Electrode Recording Tool for EXtracellular.pdf},
  number = {4}
}

@article{touretzky_whats_1989,
  title = {What’s Hidden in the Hidden Layers},
  author = {Touretzky, David S and Pomerleau, Dean A},
  date = {1989},
  journaltitle = {Byte},
  volume = {14},
  pages = {227--233},
  file = {/home/marcus/Zotero/storage/UFW4FMP7/byte-hiddenlayer-1989.pdf},
  number = {8}
}

@article{whitley_genetic_1994,
  title = {A Genetic Algorithm Tutorial},
  author = {Whitley, Darrell},
  date = {1994-06-01},
  journaltitle = {Stat. Comput.},
  volume = {4},
  pages = {65--85},
  issn = {0960-3174},
  doi = {10.1007/BF00175354},
  url = {https://doi.org/10.1007/BF00175354},
  abstract = {This tutorial covers the canonical genetic algorithm as well as more
experimental forms of genetic algorithms, including parallel island models
and parallel cellular genetic algorithms. The tutorial also illustrates
genetic search by hyperplane sampling. The theoretical foundations of
genetic algorithms are reviewed, include the schema theorem as well as
recently developed exact models of the canonical genetic algorithm.},
  file = {/home/marcus/Zotero/storage/PXNGGIRZ/Whitley - 1994 - A genetic algorithm tutorial.pdf},
  keywords = {bio module},
  number = {2}
}


